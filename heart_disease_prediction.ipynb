{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predicting Heart Disease — Playground Series S6E2\n",
        "\n",
        "**Approach**: 3-model gradient boosting ensemble (CatBoost + XGBoost + LightGBM) with:\n",
        "- Original dataset augmentation\n",
        "- Frequency + target encoding with CV-safe feature engineering\n",
        "- Clinical domain interaction features\n",
        "- Multi-seed training for stability\n",
        "- Optimized weighted rank averaging (no stacking leakage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import os\n",
        "import warnings\n",
        "from itertools import combinations\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from scipy.stats import rankdata\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "N_FOLDS = 5\n",
        "SEEDS = [42, 123, 2026]\n",
        "TARGET = \"Heart Disease\"\n",
        "\n",
        "print(\"Setup complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n",
        "\n",
        "Load competition data and the original UCI Heart Disease dataset for augmentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------- paths (Kaggle kernel vs local via kagglehub) ----------\n",
        "COMP_DIR = \"/kaggle/input/playground-series-s6e2\"\n",
        "ORIG_DIR = \"/kaggle/input/heart-disease-dataset\"\n",
        "\n",
        "if not os.path.exists(COMP_DIR):\n",
        "    import kagglehub\n",
        "    COMP_DIR = kagglehub.competition_download(\"playground-series-s6e2\")\n",
        "    ORIG_DIR = kagglehub.dataset_download(\"johnsmith88/heart-disease-dataset\")\n",
        "\n",
        "train = pd.read_csv(os.path.join(COMP_DIR, \"train.csv\"))\n",
        "test  = pd.read_csv(os.path.join(COMP_DIR, \"test.csv\"))\n",
        "\n",
        "print(f\"Train shape: {train.shape}\")\n",
        "print(f\"Test  shape: {test.shape}\")\n",
        "print(f\"\\nTarget distribution:\\n{train[TARGET].value_counts()}\")\n",
        "\n",
        "train[TARGET] = train[TARGET].map({\"Absence\": 0, \"Presence\": 1}).astype(np.uint8)\n",
        "y = train[TARGET].values\n",
        "test_ids = test[\"id\"].values\n",
        "\n",
        "# ---------- load original dataset for augmentation ----------\n",
        "ORIG_COL_MAP = {\n",
        "    \"age\": \"Age\", \"sex\": \"Sex\", \"cp\": \"Chest pain type\",\n",
        "    \"trestbps\": \"BP\", \"chol\": \"Cholesterol\",\n",
        "    \"fbs\": \"FBS over 120\", \"restecg\": \"EKG results\",\n",
        "    \"thalach\": \"Max HR\", \"exang\": \"Exercise angina\",\n",
        "    \"oldpeak\": \"ST depression\", \"slope\": \"Slope of ST\",\n",
        "    \"ca\": \"Number of vessels fluro\", \"thal\": \"Thallium\",\n",
        "    \"target\": TARGET,\n",
        "}\n",
        "\n",
        "try:\n",
        "    orig_path = os.path.join(ORIG_DIR, \"heart.csv\")\n",
        "    orig = pd.read_csv(orig_path)\n",
        "    orig.rename(columns=ORIG_COL_MAP, inplace=True)\n",
        "    orig[TARGET] = orig[TARGET].astype(np.uint8)\n",
        "\n",
        "    # align columns to match competition data (drop id if present)\n",
        "    keep = [c for c in train.columns if c not in (\"id\",)]\n",
        "    orig = orig[[c for c in keep if c in orig.columns]]\n",
        "\n",
        "    n_before = len(train)\n",
        "    train = pd.concat([train, orig], ignore_index=True)\n",
        "    y = train[TARGET].values\n",
        "    print(f\"\\nOriginal dataset appended: {len(orig)} rows  |  \"\n",
        "          f\"Train grew from {n_before} to {len(train)}\")\n",
        "except Exception as e:\n",
        "    print(f\"Original dataset not available ({e}), proceeding without it.\")\n",
        "\n",
        "X_tr_raw = train.drop(columns=[TARGET, \"id\"], errors=\"ignore\")\n",
        "X_te_raw = test.drop(columns=[\"id\"])\n",
        "\n",
        "cat_cols = [\n",
        "    \"Sex\", \"Chest pain type\", \"FBS over 120\", \"EKG results\",\n",
        "    \"Exercise angina\", \"Slope of ST\",\n",
        "    \"Number of vessels fluro\", \"Thallium\",\n",
        "]\n",
        "num_cols = [\"Age\", \"BP\", \"Cholesterol\", \"Max HR\", \"ST depression\"]\n",
        "\n",
        "print(f\"\\nFeatures — categorical: {len(cat_cols)}, numerical: {len(num_cols)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering\n",
        "\n",
        "Build frequency encodings, target encodings (CV-safe), clinical interaction features, and correlation-based interaction growth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===================== FREQUENCY ENCODING =====================\n",
        "def freq_encode(tr, te, cols):\n",
        "    tr_out = pd.DataFrame(index=tr.index)\n",
        "    te_out = pd.DataFrame(index=te.index)\n",
        "    for c in cols:\n",
        "        freq = tr[c].value_counts(normalize=True)\n",
        "        tr_out[c + \"_freq\"] = tr[c].map(freq).fillna(0)\n",
        "        te_out[c + \"_freq\"] = te[c].map(freq).fillna(0)\n",
        "    return tr_out, te_out\n",
        "\n",
        "tr_freq, te_freq = freq_encode(X_tr_raw, X_te_raw, cat_cols + num_cols)\n",
        "\n",
        "# ===================== TARGET ENCODING (CV-safe) =====================\n",
        "skf_te = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "tr_te = pd.DataFrame(0.0, index=X_tr_raw.index, columns=[c + \"_te\" for c in cat_cols + num_cols])\n",
        "te_te = pd.DataFrame(index=X_te_raw.index)\n",
        "\n",
        "global_mean = y.mean()\n",
        "\n",
        "for c in cat_cols + num_cols:\n",
        "    col_te = c + \"_te\"\n",
        "    for tr_i, val_i in skf_te.split(X_tr_raw, y):\n",
        "        means = train.iloc[tr_i].groupby(X_tr_raw.iloc[tr_i][c])[TARGET].mean()\n",
        "        tr_te.iloc[val_i, tr_te.columns.get_loc(col_te)] = (\n",
        "            X_tr_raw.iloc[val_i][c].map(means).fillna(global_mean).values\n",
        "        )\n",
        "    full_means = train.groupby(X_tr_raw[c])[TARGET].mean()\n",
        "    te_te[col_te] = X_te_raw[c].map(full_means).fillna(global_mean)\n",
        "\n",
        "# ===================== CLINICAL DOMAIN FEATURES =====================\n",
        "def add_domain_features(df, prefix=\"\"):\n",
        "    out = pd.DataFrame(index=df.index)\n",
        "    eps = 1e-6\n",
        "    out[\"ST_x_ExAngina\"] = df[\"ST depression_te\"] * df[\"Exercise angina_te\"]\n",
        "    out[\"MaxHR_x_Age\"] = df[\"Max HR_te\"] * df[\"Age_te\"]\n",
        "    out[\"Chol_x_BP\"] = df[\"Cholesterol_te\"] * df[\"BP_te\"]\n",
        "    out[\"ST_div_MaxHR\"] = df[\"ST depression_te\"] / (df[\"Max HR_te\"] + eps)\n",
        "    out[\"BP_div_Age\"] = df[\"BP_te\"] / (df[\"Age_te\"] + eps)\n",
        "    out[\"Vessels_x_Thal\"] = df[\"Number of vessels fluro_te\"] * df[\"Thallium_te\"]\n",
        "    out[\"ChestPain_x_ST\"] = df[\"Chest pain type_te\"] * df[\"ST depression_te\"]\n",
        "    return out\n",
        "\n",
        "tr_domain = add_domain_features(tr_te)\n",
        "te_domain = add_domain_features(te_te)\n",
        "\n",
        "# ===================== CORRELATION-BASED INTERACTION GROWTH =====================\n",
        "corr_scores = {}\n",
        "for a, b in combinations(tr_te.columns, 2):\n",
        "    corr_scores[(a, b)] = abs(np.corrcoef(tr_te[a], tr_te[b])[0, 1])\n",
        "\n",
        "top_pairs = sorted(corr_scores, key=corr_scores.get, reverse=True)[:10]\n",
        "\n",
        "tr_corr = pd.DataFrame(index=tr_te.index)\n",
        "te_corr = pd.DataFrame(index=te_te.index)\n",
        "for a, b in top_pairs:\n",
        "    name = f\"{a}_x_{b}\"\n",
        "    tr_corr[name] = tr_te[a] * tr_te[b]\n",
        "    te_corr[name] = te_te[a] * te_te[b]\n",
        "\n",
        "# ===================== ASSEMBLE FINAL FEATURE MATRICES =====================\n",
        "X_train = pd.concat([tr_freq, tr_te, tr_domain, tr_corr], axis=1).fillna(0).astype(np.float32)\n",
        "X_test  = pd.concat([te_freq, te_te, te_domain, te_corr], axis=1).fillna(0).astype(np.float32)\n",
        "\n",
        "print(f\"Final feature matrix: {X_train.shape[1]} features\")\n",
        "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "USE_GPU = os.path.exists(\"/opt/conda\")  # heuristic for Kaggle kernels\n",
        "\n",
        "def get_catboost_params(seed):\n",
        "    p = dict(\n",
        "        iterations=10000,\n",
        "        learning_rate=0.01,\n",
        "        depth=3,\n",
        "        loss_function=\"Logloss\",\n",
        "        eval_metric=\"AUC\",\n",
        "        auto_class_weights=\"Balanced\",\n",
        "        bootstrap_type=\"Bernoulli\",\n",
        "        subsample=0.85,\n",
        "        l2_leaf_reg=10,\n",
        "        random_strength=1.0,\n",
        "        min_data_in_leaf=50,\n",
        "        verbose=0,\n",
        "        random_seed=seed,\n",
        "        early_stopping_rounds=300,\n",
        "    )\n",
        "    if USE_GPU:\n",
        "        p[\"task_type\"] = \"GPU\"\n",
        "    return p\n",
        "\n",
        "\n",
        "def get_xgb_params(seed):\n",
        "    p = dict(\n",
        "        objective=\"binary:logistic\",\n",
        "        eval_metric=\"auc\",\n",
        "        learning_rate=0.01,\n",
        "        max_depth=3,\n",
        "        subsample=0.85,\n",
        "        colsample_bytree=0.85,\n",
        "        reg_alpha=0.05,\n",
        "        reg_lambda=1.5,\n",
        "        min_child_weight=50,\n",
        "        n_estimators=10000,\n",
        "        random_state=seed,\n",
        "        n_jobs=-1,\n",
        "        verbosity=0,\n",
        "    )\n",
        "    if USE_GPU:\n",
        "        p[\"tree_method\"] = \"hist\"\n",
        "        p[\"device\"] = \"cuda\"\n",
        "    return p\n",
        "\n",
        "\n",
        "def get_lgb_params(seed):\n",
        "    p = dict(\n",
        "        objective=\"binary\",\n",
        "        metric=\"auc\",\n",
        "        learning_rate=0.01,\n",
        "        num_leaves=20,\n",
        "        max_depth=-1,\n",
        "        subsample=0.85,\n",
        "        colsample_bytree=0.85,\n",
        "        reg_alpha=0.05,\n",
        "        reg_lambda=1.5,\n",
        "        min_child_samples=50,\n",
        "        n_estimators=10000,\n",
        "        random_state=seed,\n",
        "        n_jobs=-1,\n",
        "        verbose=-1,\n",
        "    )\n",
        "    if USE_GPU:\n",
        "        p[\"device\"] = \"gpu\"\n",
        "    return p\n",
        "\n",
        "\n",
        "print(f\"GPU mode: {USE_GPU}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Loop — Multi-Seed 5-Fold CV\n",
        "\n",
        "Each seed produces OOF and test predictions for all 3 models. Early stopping on the validation fold prevents overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_fold_models(X_tr, y_tr, X_val, y_val, X_te, seed):\n",
        "    \"\"\"Train CatBoost, XGBoost, LightGBM on one fold and return val/test probabilities.\"\"\"\n",
        "    results = {}\n",
        "\n",
        "    # --- CatBoost ---\n",
        "    cb = CatBoostClassifier(**get_catboost_params(seed))\n",
        "    cb.fit(X_tr, y_tr, eval_set=(X_val, y_val), use_best_model=True)\n",
        "    results[\"cb_val\"] = cb.predict_proba(X_val)[:, 1]\n",
        "    results[\"cb_te\"]  = cb.predict_proba(X_te)[:, 1]\n",
        "\n",
        "    # --- XGBoost ---\n",
        "    xgb = XGBClassifier(**get_xgb_params(seed), early_stopping_rounds=300)\n",
        "    xgb.fit(\n",
        "        X_tr, y_tr,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        verbose=False,\n",
        "    )\n",
        "    results[\"xgb_val\"] = xgb.predict_proba(X_val)[:, 1]\n",
        "    results[\"xgb_te\"]  = xgb.predict_proba(X_te)[:, 1]\n",
        "\n",
        "    # --- LightGBM ---\n",
        "    lgb = LGBMClassifier(**get_lgb_params(seed))\n",
        "    lgb.fit(\n",
        "        X_tr, y_tr,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        callbacks=[\n",
        "            __import__(\"lightgbm\").early_stopping(300, verbose=False),\n",
        "            __import__(\"lightgbm\").log_evaluation(0),\n",
        "        ],\n",
        "    )\n",
        "    results[\"lgb_val\"] = lgb.predict_proba(X_val)[:, 1]\n",
        "    results[\"lgb_te\"]  = lgb.predict_proba(X_te)[:, 1]\n",
        "\n",
        "    del cb, xgb, lgb\n",
        "    gc.collect()\n",
        "    return results\n",
        "\n",
        "\n",
        "# ---------- main training loop across seeds ----------\n",
        "all_oof = {m: np.zeros(len(X_train)) for m in (\"cb\", \"xgb\", \"lgb\")}\n",
        "all_test = {m: np.zeros(len(X_test)) for m in (\"cb\", \"xgb\", \"lgb\")}\n",
        "\n",
        "for seed in SEEDS:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"  SEED {seed}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=seed)\n",
        "\n",
        "    seed_oof = {m: np.zeros(len(X_train)) for m in (\"cb\", \"xgb\", \"lgb\")}\n",
        "    seed_test = {m: np.zeros(len(X_test)) for m in (\"cb\", \"xgb\", \"lgb\")}\n",
        "\n",
        "    for fold, (tr_idx, val_idx) in enumerate(skf.split(X_train, y)):\n",
        "        print(f\"\\n  Fold {fold+1}/{N_FOLDS}\")\n",
        "\n",
        "        res = train_fold_models(\n",
        "            X_train.iloc[tr_idx], y[tr_idx],\n",
        "            X_train.iloc[val_idx], y[val_idx],\n",
        "            X_test, seed + fold,\n",
        "        )\n",
        "\n",
        "        for m in (\"cb\", \"xgb\", \"lgb\"):\n",
        "            seed_oof[m][val_idx] = res[f\"{m}_val\"]\n",
        "            seed_test[m] += res[f\"{m}_te\"] / N_FOLDS\n",
        "\n",
        "        fold_scores = {m: roc_auc_score(y[val_idx], res[f\"{m}_val\"]) for m in (\"cb\", \"xgb\", \"lgb\")}\n",
        "        print(f\"    CB={fold_scores['cb']:.5f}  XGB={fold_scores['xgb']:.5f}  LGB={fold_scores['lgb']:.5f}\")\n",
        "        gc.collect()\n",
        "\n",
        "    for m in (\"cb\", \"xgb\", \"lgb\"):\n",
        "        all_oof[m] += seed_oof[m] / len(SEEDS)\n",
        "        all_test[m] += seed_test[m] / len(SEEDS)\n",
        "        print(f\"  Seed {seed} — {m.upper()} CV AUC: {roc_auc_score(y, seed_oof[m]):.5f}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"  AVERAGED ACROSS SEEDS\")\n",
        "print(f\"{'='*60}\")\n",
        "for m in (\"cb\", \"xgb\", \"lgb\"):\n",
        "    print(f\"  {m.upper()} OOF AUC: {roc_auc_score(y, all_oof[m]):.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimized Weighted Rank Averaging\n",
        "\n",
        "Find optimal blend weights by maximizing AUC on truly out-of-fold predictions. No leakage — OOF predictions were never seen during training of their respective folds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# rank-normalize OOF and test predictions\n",
        "oof_ranks = {}\n",
        "test_ranks = {}\n",
        "for m in (\"cb\", \"xgb\", \"lgb\"):\n",
        "    oof_ranks[m] = rankdata(all_oof[m]) / len(all_oof[m])\n",
        "    test_ranks[m] = rankdata(all_test[m]) / len(all_test[m])\n",
        "\n",
        "\n",
        "def neg_auc(weights):\n",
        "    \"\"\"Negative AUC for scipy minimizer (weights for cb, xgb, lgb).\"\"\"\n",
        "    w = np.abs(weights)\n",
        "    w = w / w.sum()\n",
        "    blend = w[0] * oof_ranks[\"cb\"] + w[1] * oof_ranks[\"xgb\"] + w[2] * oof_ranks[\"lgb\"]\n",
        "    return -roc_auc_score(y, blend)\n",
        "\n",
        "\n",
        "# grid search + refinement for robustness\n",
        "best_score = -1\n",
        "best_w = np.array([1/3, 1/3, 1/3])\n",
        "\n",
        "for _ in range(30):\n",
        "    w0 = np.random.dirichlet(np.ones(3))\n",
        "    res = minimize(neg_auc, w0, method=\"Nelder-Mead\",\n",
        "                   options={\"maxiter\": 2000, \"xatol\": 1e-8, \"fatol\": 1e-8})\n",
        "    w = np.abs(res.x)\n",
        "    w = w / w.sum()\n",
        "    score = -res.fun\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_w = w\n",
        "\n",
        "print(f\"Optimal weights — CB: {best_w[0]:.4f}  XGB: {best_w[1]:.4f}  LGB: {best_w[2]:.4f}\")\n",
        "print(f\"Optimized blend CV AUC: {best_score:.6f}\")\n",
        "\n",
        "# equal-weight baseline for comparison\n",
        "equal_blend = (oof_ranks[\"cb\"] + oof_ranks[\"xgb\"] + oof_ranks[\"lgb\"]) / 3\n",
        "print(f\"Equal-weight  CV AUC:   {roc_auc_score(y, equal_blend):.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# apply optimal weights to test rank predictions\n",
        "test_pred = (\n",
        "    best_w[0] * test_ranks[\"cb\"]\n",
        "    + best_w[1] * test_ranks[\"xgb\"]\n",
        "    + best_w[2] * test_ranks[\"lgb\"]\n",
        ")\n",
        "\n",
        "submission = pd.DataFrame({\"id\": test_ids, TARGET: test_pred})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(f\"Submission shape: {submission.shape}\")\n",
        "print(f\"Prediction range: [{test_pred.min():.6f}, {test_pred.max():.6f}]\")\n",
        "print(submission.head(10))\n",
        "print(\"\\nSubmission saved to submission.csv\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
